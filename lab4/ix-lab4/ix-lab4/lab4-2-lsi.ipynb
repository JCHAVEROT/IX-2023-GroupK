{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 2: Latent semantic indexing\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *K*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Mathieu Sauser*\n",
    "* *Luca Mouchel*\n",
    "* *Jérémy Chaverot*\n",
    "* *Heikel Jebali*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 2 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Don’t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import load_json\n",
    "import scipy as sp\n",
    "\n",
    "courses = load_json('data/courses.txt')\n",
    "N = len(courses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.4: Latent semantic indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('TFIDF.npy')\n",
    "docToIdx = np.load('docToIdx.npy', allow_pickle=True)\n",
    "#create a dictionnary with index as key, and document as value\n",
    "idxToDoc = dict(zip(docToIdx.item().values(), docToIdx.item().keys()))\n",
    "#create a dictionnary with document as key, and index as value\n",
    "docToIdx = dict(zip(idxToDoc.values(), idxToDoc.keys()))\n",
    "termToIdx = np.load('termToIdx.npy',  allow_pickle=True)\n",
    "#create a dictionnary with index as key, and term as value\n",
    "idxToTerm = dict(zip(termToIdx.item().values(), termToIdx.item().keys()))\n",
    "#create a dictionnary with term as key, and index as value\n",
    "termToIdx = dict(zip(idxToTerm.values(), idxToTerm.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10815, 300)\n",
      "(300,)\n",
      "(300, 854)\n"
     ]
    }
   ],
   "source": [
    "#SVD decomposition\n",
    "U, S, V = sp.sparse.linalg.svds(X, k=300)\n",
    "V = V.T\n",
    "print(U.shape)\n",
    "print(S.shape)\n",
    "print(V.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each columns of $U$ represent the influence of a terms on topics i "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index i of $S$ represent the strengh of topic i (singular value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each rows of $V^T$ represent the influence of a doc on topic i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 6.669278191262075\n",
      "=====================\n",
      "2: 4.548502896539546\n",
      "=====================\n",
      "3: 2.867597468752914\n",
      "=====================\n",
      "4: 2.196187036905732\n",
      "=====================\n",
      "5: 1.8603560966014787\n",
      "=====================\n",
      "6: 1.6821205364600134\n",
      "=====================\n",
      "7: 1.6190756001591227\n",
      "=====================\n",
      "8: 1.5728474730472282\n",
      "=====================\n",
      "9: 1.5391747914258258\n",
      "=====================\n",
      "10: 1.5254035282163458\n",
      "=====================\n",
      "11: 1.4810524769317563\n",
      "=====================\n",
      "12: 1.4664165283239408\n",
      "=====================\n",
      "13: 1.4458611065352382\n",
      "=====================\n",
      "14: 1.3898992534052956\n",
      "=====================\n",
      "15: 1.3708084249410597\n",
      "=====================\n",
      "16: 1.3617568606179178\n",
      "=====================\n",
      "17: 1.3507910883487848\n",
      "=====================\n",
      "18: 1.3426638423578032\n",
      "=====================\n",
      "19: 1.3232450150285355\n",
      "=====================\n",
      "20: 1.3116115226252492\n"
     ]
    }
   ],
   "source": [
    "#print the top 20 biggest singular value\n",
    "for i in range(20):\n",
    "    print(f\"{i+1}: {S[-(i + 1)]}\")\n",
    "    if i < 19:\n",
    "        print(\"=====================\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.5: Topic extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prendre les 10 indexes avec des valeurs max dans S. Pour U: prendres les colonnes aux indexes choppés avant et prendre les 10 valeurs max de la colonnes en question (faire pareil pour V, mais avec les lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = 10\n",
    "num_index = 10\n",
    "num_terms = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#keep num_terms (=10) largest absolute value of singular value \n",
    "index_max_value = np.argsort(np.abs(S))[-num_terms:]\n",
    "terms = [] # 10x10 matrix. For the 10 most important topics, we choose the 10 most important terms (U)\n",
    "documents = [] # 10x10 matrix. For the 10 most important topics, we choose the 10 most important documents (V)\n",
    "for i in range(num_terms):\n",
    "    j = index_max_value[i]\n",
    "    #col_u = the jth most important topics\n",
    "    col_u = U[:,j]\n",
    "    #we only keep the 10 max index of col_u\n",
    "    ten_max_index_col_u = np.argsort(col_u)[-num_terms:]\n",
    "    #we do the same for every row of V\n",
    "    col_v = V[:,j]\n",
    "    ten_max_index_row_v = np.argsort(col_v)[-num_docs:]\n",
    "    #we store the results in the 2 matrices\n",
    "    if i == 0:\n",
    "        terms = ten_max_index_col_u\n",
    "        documents = ten_max_index_row_v\n",
    "    else:\n",
    "        terms = np.vstack((terms, ten_max_index_col_u))\n",
    "        documents  = np.vstack((documents, ten_max_index_row_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 1 (singular value = 6.669278191262075)\n",
      " -top 10 terms:\n",
      "combinatorics\n",
      "finite field\n",
      "electron microscopy\n",
      "laser\n",
      "optical\n",
      "diffraction\n",
      "microscopy\n",
      "tem\n",
      "additive\n",
      "electron\n",
      "\n",
      " -top 10 documents\n",
      "MSE-655\n",
      "MSE-704\n",
      "PHYS-610\n",
      "MSE-638\n",
      "MSE-636(b)\n",
      "MSE-636(a)\n",
      "MSE-637(b)\n",
      "MSE-637(a)\n",
      "MSE-635\n",
      "MATH-636\n",
      "=============\n",
      "topic 2 (singular value = 4.548502896539546)\n",
      " -top 10 terms:\n",
      "combinatorics\n",
      "finite field\n",
      "energy transport\n",
      "diagnostics\n",
      "magnetic\n",
      "fusion\n",
      "additive\n",
      "confinement\n",
      "magnetic confinement\n",
      "plasma\n",
      "\n",
      " -top 10 documents\n",
      "PHYS-734\n",
      "BIO-630\n",
      "MATH-625(2)\n",
      "MATH-625(1)\n",
      "PHYS-445\n",
      "PHYS-423\n",
      "PHYS-424\n",
      "PHYS-732\n",
      "MATH-636\n",
      "PHYS-731\n",
      "=============\n",
      "topic 3 (singular value = 2.867597468752914)\n",
      " -top 10 terms:\n",
      "lie\n",
      "result\n",
      "emphasis\n",
      "group\n",
      "field\n",
      "finite\n",
      "combinatorial\n",
      "combinatorics\n",
      "finite field\n",
      "additive\n",
      "\n",
      " -top 10 documents\n",
      "MSE-657\n",
      "COM-102\n",
      "MATH-726(2)\n",
      "MATH-726\n",
      "MSE-804\n",
      "MATH-625\n",
      "MATH-409\n",
      "MATH-625(2)\n",
      "MATH-625(1)\n",
      "MATH-636\n",
      "=============\n",
      "topic 4 (singular value = 2.196187036905732)\n",
      " -top 10 terms:\n",
      "energy transport\n",
      "energy\n",
      "quantum\n",
      "optical\n",
      "laser\n",
      "fusion\n",
      "magnetic\n",
      "confinement\n",
      "magnetic confinement\n",
      "plasma\n",
      "\n",
      " -top 10 documents\n",
      "CH-332\n",
      "PHYS-445\n",
      "PHYS-709\n",
      "PHYS-423\n",
      "PHYS-615\n",
      "MATH-636\n",
      "PHYS-610\n",
      "PHYS-732\n",
      "PHYS-424\n",
      "PHYS-731\n",
      "=============\n",
      "topic 5 (singular value = 1.8603560966014787)\n",
      " -top 10 terms:\n",
      "arriving\n",
      "vylder\n",
      "taillieu\n",
      "corner\n",
      "simple\n",
      "complexity\n",
      "studio\n",
      "simple complexity\n",
      "house learning\n",
      "house\n",
      "\n",
      " -top 10 documents\n",
      "AR-301(d)\n",
      "MSE-648\n",
      "AR-402(y)\n",
      "AR-402(w)\n",
      "AR-401(y)\n",
      "CH-332\n",
      "MATH-625\n",
      "AR-401(w)\n",
      "AR-201(c)\n",
      "AR-202(c)\n",
      "=============\n",
      "topic 6 (singular value = 1.6821205364600134)\n",
      " -top 10 terms:\n",
      "system\n",
      "model\n",
      "house\n",
      "theory\n",
      "magnetic\n",
      "laser\n",
      "plasma\n",
      "quantum\n",
      "optical\n",
      "energy\n",
      "\n",
      " -top 10 documents\n",
      "PHYS-608\n",
      "PHYS-610\n",
      "ENG-607\n",
      "PHYS-615\n",
      "PHYS-454\n",
      "ENG-602\n",
      "PHYS-424\n",
      "PHYS-732\n",
      "AR-202(c)\n",
      "PHYS-731\n",
      "=============\n",
      "topic 7 (singular value = 1.6190756001591227)\n",
      " -top 10 terms:\n",
      "material\n",
      "theory\n",
      "question\n",
      "cell\n",
      "provide\n",
      "system\n",
      "energy\n",
      "compound\n",
      "chemical\n",
      "drug\n",
      "\n",
      " -top 10 documents\n",
      "CH-617\n",
      "PHYS-454\n",
      "MSE-627\n",
      "CH-602\n",
      "PHYS-732\n",
      "PHYS-615\n",
      "PHYS-610\n",
      "MATH-636\n",
      "PHYS-731\n",
      "CH-332\n",
      "=============\n",
      "topic 8 (singular value = 1.5728474730472282)\n",
      " -top 10 terms:\n",
      "note\n",
      "system\n",
      "animal\n",
      "design\n",
      "analog\n",
      "project\n",
      "semester\n",
      "laboratory\n",
      "ic\n",
      "semester project\n",
      "\n",
      " -top 10 documents\n",
      "HUM-422(a)\n",
      "EE-330\n",
      "EE-207\n",
      "CS-596\n",
      "BIO-689(b)\n",
      "ENV-422\n",
      "MICRO-700\n",
      "MICRO-704\n",
      "CS-699(2)\n",
      "CS-699(1)\n",
      "=============\n",
      "topic 9 (singular value = 1.5391747914258258)\n",
      " -top 10 terms:\n",
      "koch\n",
      "acceptancerejection\n",
      "hjb\n",
      "hull\n",
      "optionsdiscuss\n",
      "hedge\n",
      "bodie\n",
      "dichalcogenides\n",
      "semimetal\n",
      "administration\n",
      "\n",
      " -top 10 documents\n",
      "FIN-503\n",
      "FIN-405\n",
      "CS-323\n",
      "CS-212\n",
      "COM-417\n",
      "MATH-432\n",
      "MATH-428\n",
      "MATH-457\n",
      "MGT-690(A)\n",
      "MGT-690(B)\n",
      "=============\n",
      "topic 10 (singular value = 1.5254035282163458)\n",
      " -top 10 terms:\n",
      "fluorescence\n",
      "lightmicroscopy\n",
      "httpbiopepflch\n",
      "drug\n",
      "friction\n",
      "force\n",
      "analog\n",
      "microscopy\n",
      "contact\n",
      "administration\n",
      "\n",
      " -top 10 documents\n",
      "CS-101\n",
      "MICRO-709\n",
      "MSE-485\n",
      "MICRO-700\n",
      "ME-623\n",
      "MSE-624\n",
      "BIO-659\n",
      "BIO-478\n",
      "MGT-690(B)\n",
      "MGT-690(A)\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_terms):\n",
    "    print(f\"topic {i+1} (singular value = {S[-(i + 1)]})\")\n",
    "    print(f\" -top {num_terms} terms:\")\n",
    "    for j in terms[i]:\n",
    "        print(f\"{idxToTerm[j]}\")\n",
    "    print(f\"\\n -top {num_docs} documents\")\n",
    "    for j in documents[i]:\n",
    "        print(f\"{idxToDoc[j]}\")\n",
    "    if i < num_terms -1:\n",
    "        print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{topic 1: microscopy}\\\\ \\text{(electron) microscopy, diffraction, laser, optical}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{topic 2: electromagnetism} \\\\ \\text{magnetic, finite field, fusion, plasma}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{topic 3: algebra} \\\\ \\text{field, group, additive, finite field}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{topic 4: electromagnetism} \\\\ \\text{magnetic, plasma, magnetic, quantum}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{topic 5: architecture} \\\\ \\text{Vylder, Taillieu (both famous architect), studio, house learning}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{topic 6: quantum physics} \\\\ \\text{quantum, laser, energy, system}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{topic 7: Drug} \\\\ \\text{Drug, cell, system, compound, chemical}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{topic 8: project} \\\\ \\text{submission result, report late, semester project }$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{topic 9: It seems we have something wrong here}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{topic 10: Bioluminescence} \\\\ \\text{fluorescence, light microscopy, drug}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.6: Document similarity search in concept-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document similarity given the document's and term's index\n",
    "def sim(t, d):\n",
    "    U_t = U[t]\n",
    "    V_d = V[d]\n",
    "    sv = S * V_d\n",
    "    return np.dot(U_t, sv)/(np.linalg.norm(U_t)*np.linalg.norm(sv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we get the index of the term \"markov chain\"\n",
    "markov_chain_index = termToIdx[\"markov chain\"]\n",
    "sim_with_markov_chain = []\n",
    "\n",
    "#we compute the similarity of markov chain with every courses\n",
    "for i in range(N):\n",
    "    sim_with_markov_chain.append(sim(markov_chain_index, i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5 courses for : markov chain\n",
      "MATH-332 : 0.920654644477996\n",
      "COM-516 : 0.7783805923744408\n",
      "MGT-484 : 0.7123732607538066\n",
      "MATH-600 : 0.4306409909772205\n",
      "EE-605 : 0.2934241933500188\n"
     ]
    }
   ],
   "source": [
    "#retrieve the 5 most similar courses \n",
    "top_five_courses = np.argsort(sim_with_markov_chain)[-5:]\n",
    "print(\"top 5 courses for : markov chain\")\n",
    "for i in np.flip(top_five_courses):\n",
    "    courseId = next(iter(courses[i].values()))\n",
    "    print(f'{courseId} : {sim_with_markov_chain[i]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, the top 5 courses for markov chain was: MATH-332, COM-516, MGT-484, MATH-600, COM-512."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our top 4 is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve the index for facebook\n",
    "facebook_index = termToIdx[\"facebook\"]\n",
    "sim_with_facebook = []\n",
    "#compute the similarity of every courses with facebook\n",
    "for i in range(N):\n",
    "    sim_with_facebook.append(sim(facebook_index, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5 courses for : facebook\n",
      "EE-727 : 0.9727453128059316\n",
      "EE-593 : 0.6844992203313365\n",
      "HUM-432(a) : 0.41579967185608024\n",
      "COM-308 : 0.3944049092093338\n",
      "EE-552 : 0.22487305535582988\n"
     ]
    }
   ],
   "source": [
    "#retrieve the top 5 courses that are the most similar to facebook\n",
    "top_five_courses = np.argsort(sim_with_facebook)[-5:]\n",
    "print(\"top 5 courses for : facebook\")\n",
    "#print the top 5 courses that are the most similar to facebook\n",
    "for i in np.flip(top_five_courses):\n",
    "    courseId = next(iter(courses[i].values()))\n",
    "    print(f'{courseId} : {sim_with_facebook[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous section seems to have a bug because only the course EE-727 does not have a similarity of 0. But it's also our top 1, so it's not too bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Document-document similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use cosine similarity to find the similarity between document: $cos_{sim}(A, B) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(n, m):\n",
    "    dn = V[n]\n",
    "    dm = V[m]\n",
    "    return np.dot(dn, dm)/(np.linalg.norm(dn)*np.linalg.norm(dm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve the index of Internet analytics (IX)\n",
    "IX_index = docToIdx[\"COM-308\"]\n",
    "sim_with_ix = []\n",
    "#compute the similarity of every courses with IX\n",
    "for i in range(N):\n",
    "    sim_with_ix.append(cos_sim(IX_index, i))\n",
    "#we set the index value of IX to -10, because otherwise,\n",
    "#it's obvious that the price most similar to IX will be IX itself. \n",
    "#since cosine takes its values in [-1, 1], \n",
    "#if we set it to -10, we're certain that IX won't be the price most similar to IX.\n",
    "sim_with_ix[IX_index] = -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 courses similar to IX:\n",
      "CS-423 : 0.6441620403958727\n",
      "EE-558 : 0.5849158231059765\n",
      "CS-401 : 0.5275570322125526\n",
      "EE-724 : 0.4942567658307351\n",
      "CS-422 : 0.42301480158451943\n"
     ]
    }
   ],
   "source": [
    "top_five_courses_similar_to_IX = np.argsort(sim_with_ix)[-5:]\n",
    "print(\"Top 5 courses similar to IX:\")\n",
    "for i in np.flip(top_five_courses_similar_to_IX):\n",
    "    courseId = next(iter(courses[i].values()))\n",
    "    print(f'{courseId} : {sim_with_ix[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
