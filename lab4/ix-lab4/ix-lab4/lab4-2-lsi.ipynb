{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 2: Latent semantic indexing\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *K*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Mathieu Sauser*\n",
    "* *Luca Mouchel*\n",
    "* *Jérémy Chaverot*\n",
    "* *Heikel Jebali*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 2 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Don’t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import load_json\n",
    "import scipy as sp\n",
    "\n",
    "courses = load_json('data/courses.txt')\n",
    "N = len(courses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.4: Latent semantic indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('TFIDF.npy')\n",
    "docToIdx = np.load('docToIdx.npy', allow_pickle=True)\n",
    "idxToDoc = dict(zip(docToIdx.item().values(), docToIdx.item().keys()))\n",
    "docToIdx = dict(zip(idxToDoc.values(), idxToDoc.keys()))\n",
    "termToIdx = np.load('termToIdx.npy',  allow_pickle=True)\n",
    "idxToTerm = dict(zip(termToIdx.item().values(), termToIdx.item().keys()))\n",
    "termToIdx = dict(zip(idxToTerm.values(), idxToTerm.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "U, S, V = sp.sparse.linalg.svds(X, k=300)\n",
    "V = V.T\n",
    "print(U.shape)\n",
    "print(S.shape)\n",
    "print(V.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of U represent the influence of topics i on the columns of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index i of S represent the strengh of topic i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows of V represent the influence of topic i on the rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(f\"{i+1}: {S[-(i + 1)]}\")\n",
    "    if i < 19:\n",
    "        print(\"=====================\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.5: Topic extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prendre les 10 indexes avec des valeurs max dans S. Pour U: prendres les colonnes aux indexes choppés avant et prendre les 10 valeurs max de la colonnes en question (faire pareil pour V, mais avec les lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = 10\n",
    "num_index = 10\n",
    "num_terms = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_max_value = np.argsort(S)[-num_terms:]\n",
    "terms = [] # 10x10 matrix. For the 10 most important topics, we choose the 10 most important terms (U)\n",
    "documents = [] # 10x10 matrix. For the 10 most important topics, we choose the 10 most important documents (V)\n",
    "for i in range(num_terms):\n",
    "    j = index_max_value[i]\n",
    "    col_u = U[:,j]\n",
    "    ten_max_index_col_u = np.argsort(col_u)[-num_terms:]\n",
    "    row_v = V[j]\n",
    "    ten_max_index_row_v = np.argsort(row_v)[-num_docs:]\n",
    "    if i == 0:\n",
    "        terms = ten_max_index_col_u\n",
    "        documents = ten_max_index_row_v\n",
    "    else:\n",
    "        terms = np.vstack((terms, ten_max_index_col_u))\n",
    "        documents  = np.vstack((documents, ten_max_index_row_v))\n",
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_terms):\n",
    "    print(f\"topic {i+1}\")\n",
    "    print(f\" -top {num_terms} terms:\")\n",
    "    for j in terms[i]:\n",
    "        print(f\"{idxToTerm[j]}\")\n",
    "    print(f\"\\n -top {num_docs} documents\")\n",
    "    for j in documents[i]:\n",
    "        print(f\"{idxToDoc[j]}\")\n",
    "    if i < num_terms -1:\n",
    "        print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "il faut encore donner un label à chacun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.6: Document similarity search in concept-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(t, d):\n",
    "    U_t = U[t]\n",
    "    V_d = V[d]\n",
    "    sv = np.diag(S) @ V_d\n",
    "    return np.dot(U_t, sv)/(np.linalg.norm(U_t)*np.linalg.norm(sv)) # demander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_chain_index = termToIdx[\"markov\"] #à changer\n",
    "sim_with_markov_chain = []\n",
    "\n",
    "for i in range(N):\n",
    "    sim_with_markov_chain.append(sim(markov_chain_index, i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_five_courses = np.argsort(sim_with_markov_chain)[-5:]\n",
    "print(\"top 5 courses for : markov chain\") #à changer\n",
    "for i in np.flip(top_five_courses):\n",
    "    courseId = next(iter(courses[i].values()))\n",
    "    print(f'{courseId} : {sim_with_markov_chain[i]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook_index = termToIdx[\"facebook\"] #à changer\n",
    "sim_with_facebook = []\n",
    "\n",
    "for i in range(N):\n",
    "    sim_with_facebook.append(sim(facebook_index, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_five_courses = np.argsort(sim_with_facebook)[-5:]\n",
    "print(\"top 5 courses for : facebook\") #à changer\n",
    "for i in np.flip(top_five_courses):\n",
    "    courseId = next(iter(courses[i].values()))\n",
    "    print(f'{courseId} : {sim_with_facebook[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Document-document similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use cosine similarity to find the similarity between document: $cos_{sim}(A, B) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(n, m):\n",
    "    dn = V[n]\n",
    "    dm = V[m]\n",
    "    return np.dot(dn, dm)/(np.linalg.norm(dn)*np.linalg.norm(dm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IX_index = docToIdx[\"COM-308\"]\n",
    "sim_with_ix = []\n",
    "for i in range(N):\n",
    "    sim_with_ix.append(cos_sim(IX_index, i))\n",
    "sim_with_ix[IX_index] = -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_five_courses_similar_to_IX = np.argsort(sim_with_ix)[-5:]\n",
    "print(\"Top 5 courses similar to IX:\")\n",
    "for i in np.flip(top_five_courses_similar_to_IX):\n",
    "    courseId = next(iter(courses[i].values()))\n",
    "    print(f'{courseId} : {sim_with_ix[i]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
